# ğŸ¹ Ableton Documentation Assistant

A ğŸ¤– RAG-based chatbot that provides answers from Ableton Live's documentation using local LLM processing.

## âœ¨ Features

- ğŸ  Local LLM processing using LocalAI with GPT-4o
- ğŸ“„ PDF document processing with parallel workers
- ğŸ’¾ Vector store persistence using ChromaDB
- ğŸŒ“ Automatic dark/light mode
- â™¿ Accessibility support
- â±ï¸ Real-time initialization progress
- ğŸ§  Memory-efficient processing
- âœï¸ Markdown rendering with code highlighting
- ğŸ“š Source context display

## ğŸ”§ Prerequisites

- ğŸ“¦ Node.js 20+ LTS
- ğŸ Python 3.10 (specifically required for ChromaDB compatibility)
- ğŸ¤– LocalAI installed with GPT-4o model
- ğŸ—ƒï¸ ChromaDB server running on port 8000

### ğŸ Python Dependencies
```bash
# Create a Python 3.10 virtual environment (required for ChromaDB)
python3.10 -m venv chromadb_venv
source chromadb_venv/bin/activate

# Install required packages
pip install chromadb==1.0.7 pypdf langchain-community langchain
```

### ğŸ¤– LocalAI Setup
```bash
# Configure LocalAI with GPT-4o model
# Make sure the model is located at ~/.localai/models/gpt-4o.gguf

# For GPU acceleration (optional):
export METAL=1  # For Apple Silicon
# OR
export CUDA=1  # For NVIDIA GPUs

# Start LocalAI server
local-ai serve --models-path ~/.localai/models --config-path ~/.localai/configs --address 0.0.0.0:1234 --disable-grpc
```

## ğŸš€ Installation

1. Clone the repository:
```bash
git clone https://github.com/mrballistic/ableton-helpbot.git
cd ableton-helpbot
```

2. Install dependencies:
```bash
npm install
```

3. Place Ableton PDF documentation in the `/pdf` directory:
```
pdf/
â””â”€â”€ live12-manual-en.pdf
```

## ğŸƒâ€â™‚ï¸ Running the Application

1. Start the ChromaDB server:
```bash
./start-chromadb.sh
```

> **Important**: ChromaDB 1.0.7 requires using the dedicated `chroma run` command-line tool. If running manually, use:
> ```bash
> source chromadb_venv/bin/activate
> chroma run --host 0.0.0.0 --port 8000 --path ./vector_store
> ```
> Do NOT attempt to start ChromaDB using `python -m chromadb.app` as this won't work with version 1.0.7.

2. Start LocalAI with GPT-4o model:
```bash
# With GPU acceleration (recommended)
./update_localai_gpu.sh

# OR without GPU acceleration
local-ai serve --models-path ~/.localai/models --config-path ~/.localai/configs --address 0.0.0.0:1234 --disable-grpc
```

3. Start the application:
```bash
npm start
```

This will:
- ğŸŒ Start the React development server
- ğŸ–¥ï¸ Launch the Express backend
- ğŸ“‘ Process PDFs (first run only)
- ğŸ—„ï¸ Create and save the vector store in ChromaDB

## ğŸ—ï¸ Architecture

### ğŸŒ Frontend
- âš›ï¸ React with Material-UI
- ğŸŒ“ Automatic dark/light mode detection
- â±ï¸ Real-time initialization progress
- â™¿ Accessibility features
- ğŸ“± Responsive design
- âœï¸ Markdown rendering with syntax highlighting

### ğŸ–¥ï¸ Backend
- ğŸš‚ Express server
- ğŸ§µ PDF processing with worker threads
- ğŸ—„ï¸ Vector store management with ChromaDB
- ğŸ¤– LLM integration via LocalAI
- ğŸš¨ Error handling
- ğŸ”„ Python bridge for PDF processing

### ğŸ“Š Vector Store
- ğŸ” ChromaDB for efficient similarity search
- ğŸ’¾ Persistent storage
- ğŸ“¦ Batched processing
- ğŸ§  Memory-efficient operation
- ğŸ·ï¸ Enhanced metadata filtering

### âš™ï¸ Processing Pipeline
1. ğŸ“„ PDF Loading
   - ğŸ”„ Parallel processing with worker threads
   - ğŸ“‘ Page-range distribution
   - ğŸ“ˆ Progress tracking
   - ğŸ Python-based text extraction

2. ğŸ“ Text Processing
   - ğŸ§© Chunk generation
   - ğŸ“‹ Metadata preservation
   - ğŸ“¦ Batch processing
   - ğŸ”¤ LocalAI for embeddings

3. ğŸ—„ï¸ Vector Store
   - ğŸ§® Embedding generation via LocalAI
   - ğŸ’¾ Persistent storage with ChromaDB
   - âš¡ Fast loading
   - ğŸ” Enhanced similarity search

## ğŸ‘¨â€ğŸ’» Development

### ğŸ§ª Running Tests
```bash
# Run all tests
npm test

# Run frontend tests
npm run test:frontend

# Run backend tests
npm run test:backend

# Run specific component tests
npm test ChatBubble.test.jsx
npm test ChatInterface.test.jsx
npm test InitializationModal.test.jsx
npm test VisuallyHidden.test.jsx

# Generate coverage report
npm run test:coverage
```

### ğŸ“ Project Structure
```
â”œâ”€â”€ src/                      # Frontend source
â”‚   â”œâ”€â”€ components/           # React components
â”‚   â”‚   â”œâ”€â”€ ChatBubble.jsx   # Message bubble component
â”‚   â”‚   â”œâ”€â”€ ChatInterface.jsx # Main chat interface
â”‚   â”‚   â””â”€â”€ InitializationModal.jsx # Loading modal
â”‚   â”œâ”€â”€ helpers/             # Helper components
â”‚   â”‚   â””â”€â”€ VisuallyHidden.jsx # Accessibility helper
â”‚   â”œâ”€â”€ App.jsx             # Main React component
â”‚   â””â”€â”€ index.css           # Global styles
â”œâ”€â”€ tests/                  # Test files
â”‚   â”œâ”€â”€ components/         # Component tests
â”‚   â”‚   â”œâ”€â”€ ChatBubble.test.jsx
â”‚   â”‚   â”œâ”€â”€ ChatInterface.test.jsx
â”‚   â”‚   â””â”€â”€ InitializationModal.test.jsx
â”‚   â”œâ”€â”€ helpers/           # Helper tests
â”‚   â”‚   â””â”€â”€ VisuallyHidden.test.jsx
â”‚   â””â”€â”€ App.test.jsx       # Integration tests
â”œâ”€â”€ server.js              # Express backend
â”œâ”€â”€ worker.js             # PDF processing worker
â”œâ”€â”€ pdf/                  # PDF documentation
â”œâ”€â”€ vector_store/         # Persistent vector storage
â”‚   â”œâ”€â”€ args.json         # Vector store arguments
â”‚   â”œâ”€â”€ chroma.sqlite3    # ChromaDB database
â”‚   â””â”€â”€ docstore.json     # Document metadata
â”œâ”€â”€ configuration/        # Configuration files
â”‚   â””â”€â”€ chroma_config.json # ChromaDB configuration
â”œâ”€â”€ chromadb_venv/        # Python 3.10 virtual environment for ChromaDB
â”œâ”€â”€ start-chromadb.sh     # Script to start ChromaDB server
â””â”€â”€ update_localai_gpu.sh # Script to start LocalAI with GPU acceleration
```

### ğŸ§© Components

#### ğŸ’¬ ChatBubble
- ğŸ“ Renders user and assistant messages
- âœï¸ Markdown rendering with syntax highlighting
- ğŸ“š Source context display
- â™¿ Accessibility support

#### ğŸ’» ChatInterface
- ğŸ—¨ï¸ Main chat interface
- âŒ¨ï¸ Message input handling
- ğŸ“œ Message history management
- â³ Loading states

#### ğŸ”„ InitializationModal
- ğŸ“Š Displays initialization progress
- â±ï¸ Real-time status updates
- ğŸ“ˆ Progress tracking

#### ğŸ‘ï¸â€ğŸ—¨ï¸ VisuallyHidden
- â™¿ Accessibility helper component
- ğŸ”Š Screen reader support
- ğŸ·ï¸ ARIA announcements

### ğŸ§ª Testing Structure
- ğŸ”¬ Unit tests for each component
- ğŸ”„ Integration tests for full flows
- â™¿ Accessibility testing
- ğŸš¨ Error handling coverage
- â³ Loading state verification
- ğŸ¤ Component interaction tests

## âš¡ Performance

- ğŸ”„ First run: Processes PDFs and creates vector store (~30-60 minutes)
- âš¡ Subsequent runs: Loads existing vector store (seconds)
- ğŸ§  Memory usage: Efficient through batched processing
- ğŸ’ª CPU usage: Parallel processing based on available cores
- ğŸ–¥ï¸ GPU acceleration: Optional for LocalAI when hardware supports it

## ğŸš¨ Known Issues & Troubleshooting

### ChromaDB Issues
- ğŸ Requires specifically Python 3.10 (fails silently with newer versions like 3.13)
- ğŸƒ Must be started using the `chroma run` command (NOT `python -m chromadb.app`)
- ğŸ’“ Heartbeat check requires using API v2 endpoint
- ğŸ Needs to be started before the application

### LocalAI Issues
- ğŸ”‘ Embedding generation requires specific model name "text-embedding-3-small" for compatibility
- ğŸ–¥ï¸ GPU acceleration requires properly configured CUDA or Metal support
- ğŸ Needs to be running with correct models loaded before application usage

### General Issues
- â±ï¸ Initial PDF processing takes significant time for large documents
- ğŸ’¾ No progress persistence if initialization is interrupted
- ğŸ”„ No automatic migration path from HNSWLib to ChromaDB vectors

## â™¿ Accessibility

- ğŸ”Š Screen reader support
- âŒ¨ï¸ Keyboard navigation
- ğŸ·ï¸ ARIA labels
- ğŸ“¢ Progress announcements
- ğŸ¨ Color contrast compliance
- ğŸ” Focus management
- ğŸ‘ï¸â€ğŸ—¨ï¸ Hidden helper elements

## ğŸ‘¥ Contributing

1. ğŸ´ Fork the repository
2. ğŸŒ¿ Create a feature branch
3. ğŸ’¾ Commit changes
4. ğŸš€ Push to the branch
5. ğŸ“¬ Create a Pull Request

## ğŸ“œ License

See [LICENSE.md](license.md) for details.
